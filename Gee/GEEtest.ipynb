{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ae01eb",
   "metadata": {},
   "source": [
    "# Chapter 1: Introduction\n",
    "\n",
    "This project aims to perform flood detection using Sentinel-1 satellite imagery and the Google Earth Engine platform. By comparing radar images from pre- and post-flood periods, we can identify flooded areas and visualize water extent changes over time.\n",
    "\n",
    "- Set up the environment and initialize Google Earth Engine.\n",
    "- Define the Area of Interest (AOI) and fetch satellite images.\n",
    "- Process and visualize the data to detect changes in water-covered areas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb609c",
   "metadata": {},
   "source": [
    "# Chapter 2: Setting Up the Environment\n",
    "\n",
    "In this phase, we import necessary libraries and authenticate access to Google Earth Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19b4ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "# Initialize the Earth Engine API \n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='atu-fyp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83224aab",
   "metadata": {},
   "source": [
    "# Chapter 3: Choosing the area and time range\n",
    "\n",
    "Defining the Area of Interest (AOI)\n",
    "\n",
    "\n",
    "According to The Irish Times: https://www.irishtimes.com/ireland/2023/10/19/cork-flooding-floods-in-co-cork-absolutely-devastating-as-safety-warning-issued-to-motorists/\n",
    "\n",
    "We define the AOI for Cork, Ireland, which was heavily affected by floods in 2023. This AOI will be used to fetch and analyze satellite images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ce54e",
   "metadata": {},
   "source": [
    "Importing Libraries & Starting Earth Engine\n",
    "In this phase, we import necessary libraries and initialize Google Earth Engine to fetch and process satellite images for a specific area and time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb0af4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c78dce1ea5422891753f3b8f147d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.8691, -8.2646], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define AOI for Cork\n",
    "# Define pre-flood and post-flood dates\n",
    "#We tell the computer when to look.\n",
    "#We check images before the flood (September) and after the flood (October).\n",
    "\n",
    "# Define coordinates using lat/lon\n",
    "lat_north = 52.00904254772663\n",
    "lat_south = 51.7292195887807\n",
    "lon_west = -8.570156845611686\n",
    "lon_east = -7.959042343658562\n",
    "buffer_size = 5000  # Buffer in meters\n",
    "\n",
    "# Create the polygon using lat/lon structure\n",
    "aoi = ee.Geometry.Polygon([\n",
    "    [\n",
    "        [lon_west, lat_north],\n",
    "        [lon_west, lat_south],\n",
    "        [lon_east, lat_south],\n",
    "        [lon_east, lat_north]\n",
    "    ]\n",
    "]).buffer(buffer_size)  # Apply buffer\n",
    "\n",
    "# Initialize the map\n",
    "Map = geemap.Map(center=[51.8691, -8.2646], zoom=10)\n",
    "Map.addLayer(aoi, {'color': 'brown'}, 'Area of Interest')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0d238",
   "metadata": {},
   "source": [
    "# Chapter 4: Data collection Loading and Visualization\n",
    "\n",
    "## 4.1 Loading Sentinel-1 Data\n",
    "This section loads and filters Sentinel-1 satellite radar data for the specified flood event timeframes.  \n",
    "It prepares the data for analysis by applying filters such as date, area, and polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f143224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c78dce1ea5422891753f3b8f147d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=87015.0, center=[51.894291522466304, -8.567962646484377], controls=(WidgetControl(options=['positio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define date ranges for pre-flood and post-flood periods\n",
    "from matplotlib import image\n",
    "\n",
    "\n",
    "pre_flood_start = '2023-09-01'\n",
    "pre_flood_end = '2023-09-30'\n",
    "post_flood_start = '2023-10-01'\n",
    "post_flood_end = '2023-10-31'\n",
    "\n",
    "# Load Sentinel-1 GRD data for pre-flood period\n",
    "pre_flood_collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(pre_flood_start, pre_flood_end) \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    .select('VV')\n",
    "\n",
    "# Load Sentinel-1 GRD data for post-flood period\n",
    "post_flood_collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    .select('VV')\n",
    "\n",
    "# Get the median image for each period\n",
    "pre_flood_image = pre_flood_collection.median()\n",
    "post_flood_image = post_flood_collection.median()\n",
    "\n",
    "\n",
    "# Add pre-flood and post-flood images to the map\n",
    "Map.addLayer(pre_flood_image.clip(aoi), {'min': -20, 'max': 0}, 'Pre-Flood VV')\n",
    "Map.addLayer(post_flood_image.clip(aoi), {'min': -20, 'max': 0}, 'Post-Flood VV')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc744f",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "This section loads Sentinel-1 GRD data for pre-flood and post-flood periods and visualizes the median images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310d2bb",
   "metadata": {},
   "source": [
    "## 4.1 Water area analysis over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full time Collection\n",
    "full_collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate('2023-09-01', '2023-10-31') \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "\n",
    "# Function to calculate water extent for each image\n",
    "def calc_water_extent(image):\n",
    "    water = image.select('VV').gt(2)  # Using your existing threshold\n",
    "    area = water.multiply(ee.Image.pixelArea())\n",
    "    stats = area.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=aoi,\n",
    "        scale=30\n",
    "    )\n",
    "    return image.set({'water_area': stats.get('VV'), 'date': image.date().format()})\n",
    "\n",
    "# Apply to collection\n",
    "time_series = full_collection.map(calc_water_extent)\n",
    "\n",
    "# Export results for plotting\n",
    "timeseries_stats = time_series.aggregate_array('water_area').getInfo()\n",
    "dates = time_series.aggregate_array('date').getInfo()\n",
    "\n",
    "# Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(dates, timeseries_stats)\n",
    "plt.title('Water Area Time Series')\n",
    "plt.ylabel('Area (m²)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065db069",
   "metadata": {},
   "source": [
    "# Chapter 5: Analyzing Changes\n",
    "This section calculates the difference between pre-flood and post-flood images to detect changes in water-covered areas. A threshold is applied to identify flooded areas.\n",
    "\n",
    "## 5.1 Calculate the Difference Between Pre-Flood and Post-Flood Images\n",
    "We subtract the pre-flood image from the post-flood image to detect changes in water-covered areas. The difference image highlights areas where water levels have changed significantly.\n",
    "\n",
    "## 5.2 Thresholding to Identify Flooded Areas\n",
    "We apply a threshold to the difference image to create a binary flood mask. Pixels with values above the threshold are considered flooded. This mask is then visualized on the map.\n",
    "\n",
    "This next cell calculates the difference between the post-flood and pre-flood images by subtracting the pre-flood image from the post-flood image. The resulting difference image highlights changes in the area. The difference image is then added to the map with a color palette to visualize the changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a59d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between post-flood and pre-flood images\n",
    "difference_image = post_flood_image.subtract(pre_flood_image)\n",
    "\n",
    "# Add the difference image to the map\n",
    "Map.addLayer(difference_image.clip(aoi), {'min': -5, 'max': 5, 'palette': ['red', 'white', 'blue']}, 'Difference Image')\n",
    "Map.centerObject(aoi)\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5ed70",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "We use colors to show the changes. Red means a lot of change, blue means less change, and white means no change.\n",
    "Flood Mask: We use blue to show the places where we think there was a flood. This helps us see the flooded areas on the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edcdc83",
   "metadata": {},
   "source": [
    "## 5.2 Thresholding to Identify Flooded Areas\n",
    "We apply a threshold to the difference image to create a binary flood mask. Pixels with values above the threshold are considered flooded. This mask is then visualized on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for flood detection\n",
    "threshold = 2  # Adjust this value based on your analysis\n",
    "\n",
    "# Create a binary flood mask\n",
    "flood_mask = difference_image.gt(threshold)\n",
    "\n",
    "# Add the flood mask to the map\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'Flood Mask')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb0ad5",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "Thresholding: We decide how much change means there was a flood.  If the change is more than 2, there was a flood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413a54f",
   "metadata": {},
   "source": [
    "# Chapter 6: Exporting and Visualizing Results\n",
    "\n",
    "Export the Flood Mask\n",
    "Exporting the flood mask to Google Drive for further analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the flood mask to Google Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=flood_mask.clip(aoi),\n",
    "    description='FloodMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=30,\n",
    "    region=aoi\n",
    ")\n",
    "task.start()\n",
    "\n",
    "print(\"Export task started. Check Google Drive for the flood mask.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befd7f9",
   "metadata": {},
   "source": [
    "## 6.2 Visualizing Locally\n",
    "Visualizing the exported flood mask locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412325b2",
   "metadata": {},
   "source": [
    "Visualizing locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Check if the file exists\n",
    "import os\n",
    "file_path = r\"C:\\\\Users\\\\Neo\\\\Desktop\\\\FYP\\\\geeimages\\\\FloodMask.tif\"\n",
    "if os.path.exists(file_path):\n",
    "    # Open the exported flood mask\n",
    "    with rasterio.open(file_path) as src:\n",
    "        flood_mask_image = src.read(1)\n",
    "\n",
    "    # Display the flood mask\n",
    "    plt.imshow(flood_mask_image, cmap='Blues', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Flood Mask')\n",
    "    plt.title('Flood Mask')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f2c82",
   "metadata": {},
   "source": [
    "# Chapter 7: Refining the Threshold\n",
    "Experimenting with different threshold values (e.g., 1.5, 2.5) to improve flood detection accuracy\n",
    "Here we test different threshold values (e.g., 1.5, 2, 2.5, 3) to refine the flood detection process. Each threshold is applied to the difference image, and the resulting flood mask is visualized on the map. This helps us determine the optimal threshold for accurate flood detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4024c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a list of threshold values to test\n",
    "thresholds = [1.5, 2, 2.5, 3]\n",
    "\n",
    "# map to visualize the results\n",
    "Map = geemap.Map(center=[51.8691, -8.2646], zoom=10)\n",
    "\n",
    "# Loops through each threshold and add the flood mask to the map\n",
    "for threshold in thresholds:\n",
    "    flood_mask = difference_image.gt(threshold)\n",
    "    Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, f'Flood Mask (Threshold={threshold})')\n",
    "\n",
    "# Adds the AOI and difference image for reference\n",
    "Map.addLayer(aoi, {'color': 'red'}, 'Area of Interest')\n",
    "Map.addLayer(difference_image.clip(aoi), {'min': -5, 'max': 5, 'palette': ['red', 'white', 'blue']}, 'Difference Image')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30341cd",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "Here wer are making sure we get it right\n",
    "\n",
    "Flood Masks for Different Thresholds: We use blue to show the places where we think there was a flood for each number we tried. This helps us see how each number works.\n",
    "\n",
    "Visualizing the Results: We look at the map to see how well each number works. We add the flood areas to the map for each number and see which one shows the floods most accurately.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1869588",
   "metadata": {},
   "source": [
    "# Chapter 8: Combining Sentinel-1 and Sentinel-2 DATA\n",
    "Sentinel-2 optical data used to calculate the Normalized Difference Water Index (NDWI), which is useful for validating the flood mask derived from Sentinel-1.\n",
    "\n",
    "We load Sentinel-2 optical data for the post-flood period and calculate the NDWI, which is a useful index for detecting water bodies. The NDWI is calculated using the green (B3) and near-infrared (B8) bands. The resulting NDWI image is visualized on the map.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b49dd03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c78dce1ea5422891753f3b8f147d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=87044.0, center=[51.86970795368951, -8.264465332031252], controls=(WidgetControl(options=['position…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Loading Sentinel-2 data for the post-flood period\n",
    "#We ask Google Earth Engine for satellite images from Sentinel-2, a satellite that takes pictures of Earth. \n",
    "#We only take images from our area (Cork) and only in October.\n",
    "#We ignore pictures that have too many clouds (less than 50% clouds allowed). \n",
    "post_flood_sentinel2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))  # Filter out cloudy images\n",
    "\n",
    "# Function to calculate NDWI\n",
    "#NDWI (Normalized Difference Water Index) is a math trick to find water in a satellite image. \n",
    "# It looks at two colors:\n",
    "# B3 (Green light) \n",
    "# B8 (Near Infrared light) \n",
    "# If B3 is bright and B8 is dark, that means water! \n",
    "# We add this water-detection layer to the image.\n",
    "def add_ndwi(image):\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "# Apply NDWI calculation to the collection\n",
    "ndwi_collection = post_flood_sentinel2.map(add_ndwi)\n",
    "\n",
    "# Gets the median NDWI image\n",
    "ndwi_image = ndwi_collection.median()\n",
    "\n",
    "# Adds NDWI layer to the map\n",
    "Map.addLayer(ndwi_image.clip(aoi), {'bands': ['NDWI'], 'min': -1, 'max': 1, 'palette': ['white', 'blue']}, 'NDWI')\n",
    "ndwi_vis_params = {'bands': ['NDWI'], 'min': -0.3, 'max': 0.3, 'palette': ['white', 'blue']}\n",
    "Map.addLayer(ndwi_image.clip(aoi), ndwi_vis_params, 'NDWI')\n",
    "\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74488f",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "Sentinel-1 and Sentinel-2 We use two different satellites to get pictures. Sentinel-1 sees through clouds and Sentinel-2 sees colors.\n",
    "\n",
    "NDWI Calculation We use Sentinel-2 to find water by looking at how much green and near-infrared light is reflected.\n",
    "\n",
    "NDWI Water Mask We color the places where we think there is water using the NDWI calculation.\n",
    "\n",
    "Comparing with Flood Mask We look at both the NDWI water mask and the flood mask from Sentinel-1 to see if they match.\n",
    "\n",
    "We check if the places we found with Sentinel-1 match the places we found with Sentinel-2. This helps us make sure we are finding the floods correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-flood NDWI min/max: {'NDWI_max': 0.1608813852071762, 'NDWI_min': -0.45973318815231323}\n",
      "Post-flood NDWI min/max: {'NDWI_max': 0.22446365654468536, 'NDWI_min': -0.4603894352912903}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c78dce1ea5422891753f3b8f147d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=173670.0, center=[51.86932901232889, -8.264599594635124], controls=(WidgetControl(options=['positio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to standardize bands across all Sentinel-2 images\n",
    "def standardize_bands(image):\n",
    "    # Select only the bands we need (B3 and B8 for NDWI)\n",
    "    return image.select(['B3', 'B8'])\n",
    "\n",
    "# Load and preprocess data with band standardization\n",
    "pre_flood_sentinel2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(pre_flood_start, pre_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50)) \\\n",
    "    .map(standardize_bands)  # Force consistent bands\n",
    "\n",
    "post_flood_sentinel2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50)) \\\n",
    "    .map(standardize_bands)  # Force consistent bands\n",
    "\n",
    "# NDWI function (now works reliably since all images have B3/B8)\n",
    "def add_ndwi(image):\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "# Apply NDWI calculation\n",
    "pre_flood_ndwi = pre_flood_sentinel2.map(add_ndwi).median()\n",
    "post_flood_ndwi = post_flood_sentinel2.map(add_ndwi).median()\n",
    "\n",
    "# Print min/max NDWI values (now works without errors)\n",
    "# Here we check the NDWI values for both pre-flood and post-flood images if the post-flood NDWI isn't higher than the area may not have flooded.\n",
    "print('Pre-flood NDWI min/max:', pre_flood_ndwi.select('NDWI').reduceRegion(\n",
    "    ee.Reducer.minMax(), aoi, 1000).getInfo())\n",
    "print('Post-flood NDWI min/max:', post_flood_ndwi.select('NDWI').reduceRegion(\n",
    "    ee.Reducer.minMax(), aoi, 1000).getInfo())\n",
    "\n",
    "# Visualization (unchanged)\n",
    "Map.addLayer(pre_flood_ndwi.clip(aoi), \n",
    "             {'bands': 'NDWI', 'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'blue']}, \n",
    "             'Pre-Flood NDWI')\n",
    "Map.addLayer(post_flood_ndwi.clip(aoi), \n",
    "             {'bands': 'NDWI', 'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'blue']}, \n",
    "             'Post-Flood NDWI')\n",
    "\n",
    "# Flood detection\n",
    "flood_diff = post_flood_ndwi.select('NDWI').subtract(pre_flood_ndwi.select('NDWI'))\n",
    "Map.addLayer(flood_diff.clip(aoi), \n",
    "             {'min': 0, 'max': 0.5, 'palette': ['white', 'blue']}, \n",
    "             'NDWI Difference')\n",
    "Map.addLayer(flood_diff.gt(0.1).selfMask().clip(aoi), \n",
    "             {'palette': 'blue'}, \n",
    "             'Flooded Areas (NDWI Increase > 0.1)')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc24e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf9e45f7",
   "metadata": {},
   "source": [
    "Layer\t            Description\n",
    "Pre-Flood NDWI\t    Red/white = land, blue = pre-existing water\n",
    "Post-Flood NDWI\t    New blue areas = potential flooding\n",
    "NDWI Difference\t    White = no change, blue = increased water\n",
    "Flooded Areas\t    Only pixels where NDWI increased significantly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea95f67",
   "metadata": {},
   "source": [
    "# Chapter 9:  VALIDATING the FLOOD MASK\n",
    "Comparing the flood mask derived from Sentinel-1 with the NDWI from Sentinel-2 to validate the results.\n",
    "\n",
    "We compare the flood mask derived from Sentinel-1 with the NDWI water mask from Sentinel-2. This helps us validate the accuracy of the flood detection. Areas where both masks overlap are likely true flooded areas, while discrepancies may indicate false positives or false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a threshold for NDWI (values > 0.3 indicate water)\n",
    "# What this does:\n",
    "# We set a \"rule\" : Any place with an NDWI value higher than 0.3 is water.\n",
    "ndwi_threshold = 0.3\n",
    "ndwi = ndwi_image.select('NDWI').gt(ndwi_threshold)\n",
    "\n",
    "# Adds the NDWI water mask to the map\n",
    "Map.addLayer(ndwi.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'NDWI Water Mask')\n",
    "\n",
    "# Compares with the Sentinel-1 flood mask\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'green']}, 'Sentinel-1 Flood Mask')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787299c",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "This code creates a mask (a special filter) to highlight only the water areas on the map. It looks at the NDWI values and decides which pixels are water and which are not water.\n",
    "\n",
    "\n",
    "Sentinel-1 is another satellite (different from Sentinel-2).\n",
    "\n",
    "\n",
    "\n",
    "Validation We want to make sure that the places we found as flooded are really flooded.\n",
    "NDWI Water Mask: We use the NDWI (Normalized Difference Water Index) from Sentinel-2 to identify water areas and compare it with the flood mask from Sentinel-1.\n",
    "\n",
    "Comparing with the Sentinel-1 Flood Mask:\n",
    "\n",
    "Explanation: We add the flood mask from Sentinel-1 to the map, using green to show the areas identified as flooded. This allows us to visually compare the two masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea63db5",
   "metadata": {},
   "source": [
    "EXPORTING RESULTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e007ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export NDWI water mask\n",
    "task_ndwi = ee.batch.Export.image.toDrive(\n",
    "    image=ndwi.clip(aoi),\n",
    "    description='NDWI_WaterMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=10,\n",
    "    region=aoi\n",
    ")\n",
    "task_ndwi.start()\n",
    "\n",
    "# Export NDWI water mask\n",
    "task_ndwi = ee.batch.Export.image.toDrive(\n",
    "    image=ndwi.clip(aoi),\n",
    "    description='NDWI_WaterMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=10,\n",
    "    region=aoi\n",
    ")\n",
    "task_ndwi.start()\n",
    "print(\"Export tasks started. Check Google Drive for the validation results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# Check if the Sentinel-1 flood mask file exists\n",
    "flood_mask_path = r\"C:\\\\Users\\\\Neo\\\\Desktop\\\\FYP\\\\geeimages\\\\Sentinel1_FloodMask.tif\"\n",
    "if os.path.exists(flood_mask_path):\n",
    "    # Open the exported Sentinel-1 flood mask\n",
    "    with rasterio.open(flood_mask_path) as src:\n",
    "        flood_mask_image = src.read(1)\n",
    "\n",
    "    # Display the Sentinel-1 flood mask\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(flood_mask_image, cmap='Greens', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Sentinel-1 Flood Mask')\n",
    "    plt.title('Sentinel-1 Flood Mask')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"File not found: {flood_mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff20c89",
   "metadata": {},
   "source": [
    "# CHAPTER 10: Anazyling results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53eb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 imagery for the post-flood period\n",
    "post_flood_sentinel2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))  # Filter out cloudy images\n",
    "\n",
    "# Get the first Sentinel-2 image for visualization\n",
    "sentinel2_image = post_flood_sentinel2.first()\n",
    "\n",
    "# Add Sentinel-2 true color image to the map\n",
    "Map.addLayer(sentinel2_image.clip(aoi), {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000}, 'Sentinel-2 True Color')\n",
    "\n",
    "# Add the flood mask and NDWI water mask for comparison\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'green']}, 'Sentinel-1 Flood Mask')\n",
    "Map.addLayer(ndwi.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'NDWI Water Mask')\n",
    "\n",
    "# Add the AOI for reference\n",
    "Map.addLayer(aoi, {'color': 'red'}, 'Area of Interest')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For demonstration, we'll use the NDWI water mask as validation data\n",
    "reference_data = ndwi\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_matrix = flood_mask.add(reference_data.multiply(2)).clip(aoi)\n",
    "\n",
    "# Add confusion matrix to the map\n",
    "Map.addLayer(confusion_matrix, {'min': 0, 'max': 3, 'palette': ['white', 'green', 'blue', 'red']}, 'Confusion Matrix')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c688aae",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "The NDWI water mask (blue) represents water bodies detected by Sentinel-2.\n",
    "\n",
    "The Sentinel-1 flood mask (green) represents flooded areas detected by Sentinel-1.\n",
    "\n",
    "Overlaying the two masks to see how well they align.\n",
    "\n",
    "Here we look for areas where both masks (blue and green) overlap. These are likely true flooded areas.\n",
    "\n",
    "Areas where only one mask detects water may indicate false positives or false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffad09",
   "metadata": {},
   "source": [
    "Quantitive Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a threshold for NDWI (values > 0.3 indicate water)\n",
    "ndwi_threshold = 0.3\n",
    "ndwi = ndwi_image.select('NDWI').gt(ndwi_threshold)\n",
    "\n",
    "# Adds the NDWI water mask to the map\n",
    "Map.addLayer(ndwi.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'NDWI Water Mask')\n",
    "\n",
    "# For demonstration, we'll use the NDWI water mask as ground truth\n",
    "reference_data = ndwi\n",
    "\n",
    "# Combine flood mask and NDWI water mask to generate a confusion matrix\n",
    "# Values:\n",
    "# 0 = Neither predicted nor actual (True Negative)\n",
    "# 1 = Predicted flood, not actual (False Positive)\n",
    "# 2 = Actual flood, not predicted (False Negative)\n",
    "# 3 = Correctly predicted flood (True Positive)\n",
    "confusion_matrix = flood_mask.add(reference_data.multiply(2)).clip(aoi)\n",
    "\n",
    "\n",
    "# Adds confusion matrix to the map\n",
    "Map.addLayer(confusion_matrix, {'min': 0, 'max': 3, 'palette': ['white', 'green', 'blue', 'red']}, 'Confusion Matrix')\n",
    "Map.centerObject(aoi)\n",
    "Map\n",
    "\n",
    "# Calculates true positives, false positives, and false negatives\n",
    "true_positives = confusion_matrix.eq(3).rename('TP')\n",
    "false_positives = confusion_matrix.eq(1).rename('FP')\n",
    "false_negatives = confusion_matrix.eq(2).rename('FN')\n",
    "\n",
    "# Sums the values over the AOI\n",
    "tp_sum = true_positives.reduceRegion(ee.Reducer.sum(), aoi, 30).get('TP').getInfo()\n",
    "fp_sum = false_positives.reduceRegion(ee.Reducer.sum(), aoi, 30).get('FP').getInfo()\n",
    "fn_sum = false_negatives.reduceRegion(ee.Reducer.sum(), aoi, 30).get('FN').getInfo()\n",
    "\n",
    "# Calculates metrics\n",
    "accuracy = (tp_sum) / (tp_sum + fp_sum + fn_sum)\n",
    "precision = tp_sum / (tp_sum + fp_sum)\n",
    "recall = tp_sum / (tp_sum + fn_sum)\n",
    "\n",
    "# Prints the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Visualize flood mask and verified data\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'red']}, 'Flood Mask')\n",
    "Map.addLayer(reference_data.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'Ground Truth')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cc1b5",
   "metadata": {},
   "source": [
    "EXPLANATION \n",
    "\n",
    "True Positives (TP): Areas where both Sentinel-1 and NDWI detect water.\n",
    "\n",
    "False Positives (FP): Areas where Sentinel-1 detects water, but NDWI does not.\n",
    "\n",
    "False Negatives (FN): Areas where NDWI detects water, but Sentinel-1 does not.\n",
    "\n",
    "Accuracy: Percentage of correctly identified flooded areas.\n",
    "\n",
    "Precision: Percentage of detected floods that are correct.\n",
    "\n",
    "Recall: Percentage of actual floods that were detected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
