{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7dd860",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Floods are among the most devastating natural disasters, causing significant economic, social, and environmental damage. \n",
    "Timely and accurate flood detection is crucial for disaster response and mitigation efforts. \n",
    "This project presents a flood detection system based on Sentinel-1 Synthetic Aperture Radar (SAR) data, validated against a water mask derived from Sentinel-2 optical imagery using the Normalized Difference Water Index (NDWI).\n",
    "\n",
    "The methodology involved the preprocessing of SAR and optical data, calculation of NDWI, generation of flood masks, and validation through a confusion matrix analysis.\n",
    "Results showed that the SAR-based flood mask achieved a precision of 100%, indicating a high reliability in positively identified flood areas, but a recall of 6.39%, highlighting missed flood detections.\n",
    "\n",
    "Limitations included the absence of validation data and the influence of cloud cover on optical imagery. \n",
    "Despite these challenges, the project demonstrated the potential of remote sensing technologies for flood detection and provides a foundation for future work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb609c",
   "metadata": {},
   "source": [
    "# Setting Up the Environment\n",
    "\n",
    "Importing Libraries & Starting Earth Engine\n",
    "In this phase, we import necessary libraries and initialize Google Earth Engine to fetch and process satellite images for a specific area and time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import requests\n",
    "import rasterio\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Earth Engine API \n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='atu-fyp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83224aab",
   "metadata": {},
   "source": [
    "## Choosing the area and time range\n",
    "\n",
    "We define the AOI for Cork, Ireland, which was heavily affected by floods in 2023. This AOI will be used to fetch and analyze satellite images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb0af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Area of Interest (AOI)\n",
    "def create_aoi(lat_north, lat_south, lon_west, lon_east, buffer_size=1000):\n",
    "    \"\"\"\n",
    "    Creates an AOI polygon with a buffer.\n",
    "    Args:\n",
    "        lat_north (float): Northern latitude.\n",
    "        lat_south (float): Southern latitude.\n",
    "        lon_west (float): Western longitude.\n",
    "        lon_east (float): Eastern longitude.\n",
    "        buffer_size (int): Buffer size in meters.\n",
    "    Returns:\n",
    "        ee.Geometry: Buffered AOI polygon.\n",
    "    \"\"\"\n",
    "    return ee.Geometry.Polygon([\n",
    "        [\n",
    "            [lon_west, lat_north],\n",
    "            [lon_west, lat_south],\n",
    "            [lon_east, lat_south],\n",
    "            [lon_east, lat_north]\n",
    "        ]\n",
    "    ]).buffer(buffer_size)\n",
    "\n",
    "\n",
    "aoi = create_aoi(51.95, 51.80, -8.60, -8.15)\n",
    "\n",
    "# Initialize the map\n",
    "Map = geemap.Map(center=[51.8691, -8.2646], zoom=10)\n",
    "Map.addLayer(aoi, {'color': 'brown'}, 'Area of Interest')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14c907",
   "metadata": {},
   "source": [
    "## Loading Sentinel-1 SAR Images\n",
    "\n",
    "This function loads Sentinel-1 radar images for a given date range and area.  \n",
    "We use it to get a clean image before and after the flood for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54863d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date ranges for pre-flood and post-flood periods\n",
    "def define_date_ranges(pre_start, pre_end, post_start, post_end):\n",
    "    \"\"\"\n",
    "    Defines date ranges for pre-flood and post-flood periods.\n",
    "    Args:\n",
    "        pre_start (str): Start date for pre-flood period (YYYY-MM-DD).\n",
    "        pre_end (str): End date for pre-flood period (YYYY-MM-DD).\n",
    "        post_start (str): Start date for post-flood period (YYYY-MM-DD).\n",
    "        post_end (str): End date for post-flood period (YYYY-MM-DD).\n",
    "    Returns:\n",
    "        dict: Dictionary containing the date ranges.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'pre_flood_start': pre_start,\n",
    "        'pre_flood_end': pre_end,\n",
    "        'post_flood_start': post_start,\n",
    "        'post_flood_end': post_end\n",
    "    }\n",
    "\n",
    "\n",
    "date_ranges = define_date_ranges('2023-09-01', '2023-09-30', '2023-10-01', '2023-10-31')\n",
    "pre_flood_start = date_ranges['pre_flood_start']\n",
    "pre_flood_end = date_ranges['pre_flood_end']\n",
    "post_flood_start = date_ranges['post_flood_start']\n",
    "post_flood_end = date_ranges['post_flood_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa0d238",
   "metadata": {},
   "source": [
    "# Data collection Loading and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef8d380",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 Loading Sentinel-1 Data\n",
    "This section loads and filters Sentinel-1 satellite radar data for the specified flood event timeframes.  \n",
    "It prepares the data for analysis by applying filters such as date, area, and polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-1 data\n",
    "def load_sentinel1_data(start_date, end_date, aoi):\n",
    "    \"\"\"\n",
    "    Loads Sentinel-1 GRD data for a given date range and AOI.\n",
    "    Args:\n",
    "        start_date (str): Start date (YYYY-MM-DD).\n",
    "        end_date (str): End date (YYYY-MM-DD).\n",
    "        aoi (ee.Geometry): Area of Interest.\n",
    "    Returns:\n",
    "        ee.Image: Median composite of Sentinel-1 data.\n",
    "    \"\"\"\n",
    "    return ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "        .filterBounds(aoi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "        .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "        .select('VV').median()\n",
    "\n",
    "pre_flood_image = load_sentinel1_data(pre_flood_start, pre_flood_end, aoi)\n",
    "post_flood_image = load_sentinel1_data(post_flood_start, post_flood_end, aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we add the pre-flood and post-flood Sentinel-1 radar images to the map.  \n",
    "pre_flood_image = load_sentinel1_data(pre_flood_start, pre_flood_end, aoi)\n",
    "post_flood_image = load_sentinel1_data(post_flood_start, post_flood_end, aoi)\n",
    "\n",
    "# Add pre-flood and post-flood images to the map\n",
    "Map.addLayer(pre_flood_image.clip(aoi), {'min': -20, 'max': 0}, 'Pre-Flood VV')\n",
    "Map.addLayer(post_flood_image.clip(aoi), {'min': -20, 'max': 0}, 'Post-Flood VV')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88d1898",
   "metadata": {},
   "source": [
    "## Exporting Pre- and Post-Flood Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c37a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export folder and filenames\n",
    "export_folder = r'C:\\Users\\Neo\\Desktop\\FYP\\Flood-Detection-System-FYP\\Gee\\images\\flood_images'\n",
    "pre_flood_filename = 'Pre_Flood_VV.png'\n",
    "post_flood_filename = 'Post_Flood_VV.png'\n",
    "\n",
    "# Ensure the export folder exists\n",
    "os.makedirs(export_folder, exist_ok=True)\n",
    "\n",
    "# Function to download thumbnails directly from Earth Engine to a local folder.\n",
    "def download_image_as_png(image, filename, vis_params=None):\n",
    "    try:\n",
    "        # Generate the thumbnail URL\n",
    "        url = image.getThumbURL({\n",
    "            'dimensions': 1024,  # Set the dimensions of the PNG\n",
    "            'region': aoi.getInfo()['coordinates'],  # Export region\n",
    "            'format': 'png',  # Save as PNG\n",
    "            'min': -20,  # Minimum value for visualization\n",
    "            'max': 0,  # Maximum value for visualization\n",
    "            'palette': ['black', 'white']  # Grayscale palette\n",
    "        })\n",
    "        # Download the image\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            filepath = os.path.join(export_folder, filename)\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Saved: {filepath}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}. HTTP Status Code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "# Download Pre-Flood VV image as PNG\n",
    "download_image_as_png(pre_flood_image, pre_flood_filename)\n",
    "\n",
    "# Download Post-Flood VV image as PNG\n",
    "download_image_as_png(post_flood_image, post_flood_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310d2bb",
   "metadata": {},
   "source": [
    "## Water Area Time Series Analysis\n",
    "\n",
    "Here we calculate the water extent for each Sentinel-1 image during the flood period.  \n",
    "The water area is estimated by classifying pixels with low VV backscatter, and the results are plotted over time to show how flooding evolved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_collection = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate('2023-09-01', '2023-10-31') \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
    "\n",
    "# Function to calculate water extent for each image\n",
    "def calc_water_extent(image):\n",
    "    water = image.select('VV').lt(-15)  # Pixels with VV backscatter below -15 dB are classified as floodwater.\n",
    "    area = water.multiply(ee.Image.pixelArea())\n",
    "    stats = area.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=aoi,\n",
    "        scale=30\n",
    "    )\n",
    "    return image.set({'water_area': stats.get('VV'), 'date': image.date().format()})\n",
    "\n",
    "# Apply function to image collection\n",
    "time_series = full_collection.map(calc_water_extent)\n",
    "\n",
    "# Export results for plotting\n",
    "timeseries_stats_m2 = time_series.aggregate_array('water_area').getInfo()\n",
    "dates = time_series.aggregate_array('date').getInfo()\n",
    "\n",
    "# Convert area from m² to km²\n",
    "timeseries_stats_km2 = [value / 1e6 if value else 0 for value in timeseries_stats_m2]\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, timeseries_stats_km2, marker='o')\n",
    "plt.title('Water Area Time Series')\n",
    "plt.ylabel('Area (km²)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.savefig('images/charts/Water_Area_Time_Series_km2.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065db069",
   "metadata": {},
   "source": [
    "## Analyzing Flood Related Changes\n",
    "This section calculates the difference between pre-flood and post-flood images to detect changes in water-covered areas. A threshold is applied to identify flooded areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf27f1",
   "metadata": {},
   "source": [
    "## Exporting the Difference Image\n",
    "\n",
    "We calculate the difference between the post-flood and pre-flood radar images to highlight flood changes.  \n",
    "The difference image is saved as a PNG file with a color palette showing where significant changes happened.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a59d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the export folder and filename\n",
    "export_folder = r'C:\\Users\\Neo\\Desktop\\FYP\\Flood-Detection-System-FYP\\Gee\\images\\flood_images'\n",
    "filename = 'Difference_VV.png'\n",
    "\n",
    "# Ensure the export folder exists\n",
    "os.makedirs(export_folder, exist_ok=True)\n",
    "\n",
    "# Calculate the difference between post-flood and pre-flood images\n",
    "difference_image = post_flood_image.subtract(pre_flood_image)\n",
    "\n",
    "# Debug: Print the difference image info\n",
    "print(\"Difference Image Info:\", difference_image.getInfo())\n",
    "\n",
    "def download_difference_image_as_png(image, filename):\n",
    "    try:\n",
    "        # Generate the thumbnail URL\n",
    "        url = image.getThumbURL({\n",
    "            'dimensions': 1024,  # Set the dimensions of the PNG\n",
    "            'region': aoi.getInfo()['coordinates'],  # Export region\n",
    "            'format': 'png',  # Save as PNG\n",
    "            'min': -5,  # Minimum value for visualization\n",
    "            'max': 5,  # Maximum value for visualization\n",
    "            'palette': ['red', 'white', 'blue']  # Color palette for difference\n",
    "        })\n",
    "\n",
    "        # Debug: Print the generated URL\n",
    "        print(f\"Generated URL: {url}\")\n",
    "\n",
    "        # Download the image\n",
    "        response = requests.get(url, stream=True)\n",
    "        # Debug: Print the HTTP status code\n",
    "        print(f\"HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            filepath = os.path.join(export_folder, filename)\n",
    "            # Debug: Print the file path\n",
    "            print(f\"Saving to: {filepath}\")\n",
    "\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Saved: {filepath}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}. HTTP Status Code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "# Download the difference image\n",
    "download_difference_image_as_png(difference_image, filename)\n",
    "\n",
    "# Add the difference image to the map\n",
    "Map.addLayer(difference_image.clip(aoi), {'min': -5, 'max': 5, 'palette': ['blue', 'white', 'red']}, 'Difference Image')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5ed70",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "We use colors to show the changes. Red means a lot of change, blue means less change, and white means no change.\n",
    "Flood Mask: We use blue to show the places where we think there was a flood. This helps us see the flooded areas on the map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edcdc83",
   "metadata": {},
   "source": [
    "# Creating the Flood Mask\n",
    "\n",
    "We apply a threshold to the difference image to detect flooded areas.  \n",
    "Pixels above the threshold are classified as flooded and visualized on the map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7107fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for flood detection\n",
    "threshold = 2  # Adjust this value based on your analysis\n",
    "\n",
    "# Create a binary flood mask\n",
    "flood_mask = difference_image.gt(threshold)\n",
    "\n",
    "# Add the flood mask to the map\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'Flood Mask')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb0ad5",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "Thresholding: We decide how much change means there was a flood.  If the change is more than 2, there was a flood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3413a54f",
   "metadata": {},
   "source": [
    "## Exporting the Flood Mask\n",
    "\n",
    "The final flood mask is exported to Google Drive.  \n",
    "The export runs as a background task and saves the result at 30-meter resolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the flood mask to Google Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=flood_mask.clip(aoi),\n",
    "    description='FloodMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=30,\n",
    "    region=aoi\n",
    ")\n",
    "task.start()\n",
    "\n",
    "print(\"Export task started. Check Google Drive for the flood mask.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befd7f9",
   "metadata": {},
   "source": [
    "## Loading and Displaying the Exported Flood Mask\n",
    "\n",
    "We check if the exported flood mask file exists locally.  \n",
    "If it does, we open it and display the flood areas using a simple blue color map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9239c65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if the file exists\n",
    "import os\n",
    "file_path = r\"C:\\\\Users\\\\Neo\\\\Desktop\\\\FYP\\\\geeimages\\\\FloodMask.tif\"\n",
    "if os.path.exists(file_path):\n",
    "    # Open the exported flood mask\n",
    "    with rasterio.open(file_path) as src:\n",
    "        flood_mask_image = src.read(1)\n",
    "\n",
    "    # Display the flood mask\n",
    "    plt.imshow(flood_mask_image, cmap='Blues', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Flood Mask')\n",
    "    plt.title('Flood Mask')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf65a9",
   "metadata": {},
   "source": [
    "## Satellite Resolution Comparison\n",
    "\n",
    "Here we compare Sentinel-2, Landsat-8, and Sentinel-1 based on their spatial and temporal resolution.  \n",
    "This helps understand which satellite offers better detail and more frequent observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9c560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "satellites = ['Sentinel-2', 'Landsat-8', 'Sentinel-1']\n",
    "\n",
    "# Spatial resolution in meters for each satellite (lower = better detail)\n",
    "spatial_resolution = [10, 30, 10]\n",
    "\n",
    "# Temporal resolution in days (how often the satellite revisits the same location)\n",
    "temporal_resolution = [5, 16, 6]\n",
    "\n",
    "# Create an index for the x-axis (one for each satellite)\n",
    "x = range(len(satellites))\n",
    "\n",
    "# Define the width of each bar\n",
    "bar_width = 0.35\n",
    "\n",
    "# Create a new figure and axis object\n",
    "fig, ax = plt.subplots(figsize=(8, 5))  # Set figure size\n",
    "\n",
    "# Plot the spatial resolution bars (shift left by half bar width)\n",
    "ax.bar([i - bar_width/2 for i in x], spatial_resolution,\n",
    "       width=bar_width, label='Spatial Resolution (m)')\n",
    "\n",
    "# Plot the temporal resolution bars (shift right by half bar width)\n",
    "ax.bar([i + bar_width/2 for i in x], temporal_resolution,\n",
    "       width=bar_width, label='Temporal Resolution (days)')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Satellite')\n",
    "ax.set_title('Comparison of Spatial and Temporal Resolution')\n",
    "ax.set_xticks(x)  # Set the positions of the x-axis ticks\n",
    "ax.set_xticklabels(satellites)  # Label the x-axis ticks with satellite names\n",
    "ax.legend()  # Add a legend\n",
    "ax.grid(True, linestyle='--', alpha=0.5)  # Optional: add light grid lines\n",
    "\n",
    "# Adjust layout to avoid clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the chart as an image file\n",
    "plt.savefig('images/charts/satellite_comparison.png')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f2c82",
   "metadata": {},
   "source": [
    "## Visualizing Different Flood Detection Thresholds\n",
    "\n",
    "We test multiple thresholds to see how they affect flood detection results.  \n",
    "Each threshold generates a different flood mask layer, helping us choose the best value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4024c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a list of threshold values to test\n",
    "thresholds = [1.5, 2, 2.5, 3]\n",
    "\n",
    "# map to visualize the results\n",
    "Map = geemap.Map(center=[51.8691, -8.2646], zoom=10)\n",
    "\n",
    "# Loops through each threshold and add the flood mask to the map\n",
    "for threshold in thresholds:\n",
    "    flood_mask = difference_image.gt(threshold)\n",
    "    Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, f'Flood Mask (Threshold={threshold})')\n",
    "\n",
    "# Adds the AOI and difference image for reference\n",
    "Map.addLayer(aoi, {'color': 'red'}, 'Area of Interest')\n",
    "Map.addLayer(difference_image.clip(aoi), {'min': -5, 'max': 5, 'palette': ['red', 'white', 'blue']}, 'Difference Image')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30341cd",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "Here wer are making sure we get it right\n",
    "\n",
    "Flood Masks for Different Thresholds: Using blue to show the places where we think there was a flood for each number we tried. This helps see how each number works.\n",
    "\n",
    "Visualizing the Results: See how well each number works. Addind the flood areas to the map for each number and see which one shows the floods most accurately.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1869588",
   "metadata": {},
   "source": [
    "# Calculating NDWI from Post-Flood Sentinel-2 Images\n",
    "\n",
    "We load post-flood Sentinel-2 images, calculate the NDWI index to detect water bodies,  \n",
    "and create a median composite. The NDWI layer is then added to the map for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49dd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 images after the flood\n",
    "post_flood_sentinel2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 70))\n",
    "\n",
    "# Function to calculate NDWI\n",
    "def calculate_ndwi(image):\n",
    "    \"\"\"\n",
    "    Calculates NDWI for a given Sentinel-2 image.\n",
    "    Args:\n",
    "        image (ee.Image): A Sentinel-2 image.\n",
    "    Returns:\n",
    "        ee.Image: The input image with an added 'NDWI' band.\n",
    "    \"\"\"\n",
    "    return image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "\n",
    "# Apply NDWI calculation\n",
    "ndwi_collection = post_flood_sentinel2.map(calculate_ndwi)\n",
    "\n",
    "# Create a median composite NDWI image\n",
    "ndwi_image = ndwi_collection.median()\n",
    "\n",
    "# Visualization parameters\n",
    "ndwi_vis_params = {\n",
    "    'bands': ['NDWI'],\n",
    "    'min': -0.3,\n",
    "    'max': 0.3,\n",
    "    'palette': ['white', 'blue']\n",
    "}\n",
    "\n",
    "# Add NDWI layer to the map\n",
    "Map.addLayer(ndwi_image.clip(aoi), ndwi_vis_params, 'NDWI')\n",
    "Map.centerObject(aoi)\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e74488f",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "Sentinel-1 and Sentinel-2 We use two different satellites to get pictures. Sentinel-1 sees through clouds and Sentinel-2 sees colors.\n",
    "\n",
    "NDWI Calculation We use Sentinel-2 to find water by looking at how much green and near-infrared light is reflected.\n",
    "\n",
    "NDWI Water Mask We color the places where we think there is water using the NDWI calculation.\n",
    "\n",
    "Comparing with Flood Mask We look at both the NDWI water mask and the flood mask from Sentinel-1 to see if they match.\n",
    "\n",
    "We check if the places we found with Sentinel-1 match the places we found with Sentinel-2. This helps us make sure we are finding the floods correctly.\n",
    "\n",
    "The NDWI layer is added to visualize and detect areas covered by water, enabling the identification of flood-affected zones by enhancing the contrast between water bodies and land in post-flood satellite pictures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92bcd56",
   "metadata": {},
   "source": [
    "## Detecting Flooded Areas with NDWI Change\n",
    "\n",
    "We calculate NDWI before and after the flood, then compare them to highlight flooded areas.  \n",
    "Regions with a significant NDWI increase are classified as flooded and visualized on the map.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize bands\n",
    "def standardize_bands(image):\n",
    "    return image.select(['B3', 'B8'])\n",
    "\n",
    "# Function to add NDWI band\n",
    "def add_ndwi(image):\n",
    "    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "    return image.addBands(ndwi)\n",
    "\n",
    "# Load pre- and post-flood images\n",
    "def load_sentinel2(start_date, end_date):\n",
    "    return ee.ImageCollection('COPERNICUS/S2') \\\n",
    "        .filterBounds(aoi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50)) \\\n",
    "        .map(standardize_bands)\n",
    "\n",
    "pre_flood = load_sentinel2(pre_flood_start, pre_flood_end).map(add_ndwi).median()\n",
    "post_flood = load_sentinel2(post_flood_start, post_flood_end).map(add_ndwi).median()\n",
    "\n",
    "# Print min/max NDWI values\n",
    "print('Pre-flood NDWI min/max:', pre_flood.select('NDWI').reduceRegion(ee.Reducer.minMax(), aoi, 1000).getInfo())\n",
    "print('Post-flood NDWI min/max:', post_flood.select('NDWI').reduceRegion(ee.Reducer.minMax(), aoi, 1000).getInfo())\n",
    "\n",
    "# Visualization\n",
    "ndwi_vis_params = {'bands': 'NDWI', 'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'blue']}\n",
    "Map.addLayer(pre_flood.clip(aoi), ndwi_vis_params, 'Pre-Flood NDWI')\n",
    "Map.addLayer(post_flood.clip(aoi), ndwi_vis_params, 'Post-Flood NDWI')\n",
    "\n",
    "# Flood detection\n",
    "flood_diff = post_flood.select('NDWI').subtract(pre_flood.select('NDWI'))\n",
    "\n",
    "# Mask areas with significant NDWI increase (>0.1) to highlight flooded areas\n",
    "flooded_areas = flood_diff.gt(0.05).And(post_flood.select('NDWI').gt(0)).selfMask()\n",
    "Map.addLayer(flooded_areas.clip(aoi), \n",
    "             {'palette': 'blue'}, \n",
    "             'Flooded Areas (NDWI Increase > 0.1)')\n",
    "\n",
    "# Show the difference in NDWI\n",
    "Map.addLayer(flood_diff.clip(aoi), {'min': 0, 'max': 0.5, 'palette': ['white', 'blue']}, 'NDWI Difference')\n",
    "Map.addLayer(flood_diff.gt(0.1).selfMask().clip(aoi), {'palette': 'blue'}, 'Flooded Areas (NDWI Increase > 0.1)')\n",
    "Map.centerObject(aoi)\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93faa631",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "| Step | What Happens? |\n",
    "|:----|:--------------|\n",
    "| **Pick bands** | Choose green and infrared light to detect water |\n",
    "| **Add NDWI** | Create a \"water index\" to highlight water presence |\n",
    "| **Load images** | Bring in pre-flood and post-flood satellite photos |\n",
    "| **Filter clouds** | Use only clear satellite images |\n",
    "| **Calculate difference** | Find where water coverage increased |\n",
    "| **Highlight floods** | Show newly flooded areas in blue on the map |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e45f7",
   "metadata": {},
   "source": [
    "## Interpretation of the Outputs\n",
    "\n",
    "| **Layer**            | **Description**                                           |\n",
    "|----------------------|-----------------------------------------------------------|\n",
    "| Pre-Flood NDWI       | Red/white = land, blue = pre-existing water               |\n",
    "| Post-Flood NDWI      | New blue areas = potential flooding                       |\n",
    "| NDWI Difference      | White = no change, blue = increased water                 |\n",
    "| Flooded Areas        | Only pixels where NDWI increased significantly            |\n",
    "\n",
    "---\n",
    "\n",
    "- If there was a flood, **Post-flood NDWI_max** should be **higher** than **Pre-flood NDWI_max**.\n",
    "- **Water** usually gives **high positive NDWI** (closer to +1).\n",
    "- **Dry land** has **low or negative NDWI** (around 0 or negative values).\n",
    "\n",
    "The final flood detection (`flood_diff.gt(0.1)`) gives:\n",
    "- A **masked image** where only pixels that increased NDWI by more than 0.1 are shown.\n",
    "- These pixels are interpreted as **\"new water\" (flooded areas)**.\n",
    "\n",
    "If there was **no flood**, this layer will look almost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782667c",
   "metadata": {},
   "source": [
    "## Loading and Masking Sentinel-2 Images\n",
    "\n",
    "We load Sentinel-2 surface reflectance images and apply cloud masking to improve flood detection.  \n",
    "Both raw and masked images are visualized to show the difference in quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0429c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Load and Mask Sentinel-2 Data \n",
    "def load_and_mask(start_date, end_date):\n",
    "    \"\"\"Loads and masks clouds in Sentinel-2 SR data for a given date range\"\"\"\n",
    "    collection = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "        .filterBounds(aoi) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 50))\n",
    "\n",
    "    def mask_clouds(image):\n",
    "        cloud_prob = image.select('MSK_CLDPRB')\n",
    "        return image.updateMask(cloud_prob.lt(50))\n",
    "\n",
    "    return collection.map(mask_clouds).median()\n",
    "\n",
    "# Load cloud-masked images from the COPERNICUS/S2_SR dataset\n",
    "pre_flood = load_and_mask(pre_flood_start, pre_flood_end)\n",
    "post_flood = load_and_mask(post_flood_start, post_flood_end)\n",
    "\n",
    "# Load Raw (Unmasked) Data for Comparison\n",
    "raw_pre_flood = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(pre_flood_start, pre_flood_end) \\\n",
    "    .median()\n",
    "\n",
    "raw_post_flood = ee.ImageCollection('COPERNICUS/S2_SR') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .median()\n",
    "\n",
    "# Visualization Parameters\n",
    "vis_params = {\n",
    "    'bands': ['B4', 'B3', 'B2'],\n",
    "    'min': 0,\n",
    "    'max': 10000,\n",
    "    'gamma': 1.3\n",
    "}\n",
    "\n",
    "Map.addLayer(raw_post_flood.clip(aoi), vis_params, 'Raw Sentinel-2 Post-Flood')\n",
    "Map.addLayer(post_flood.clip(aoi), vis_params, 'Masked Post-Flood')\n",
    "\n",
    "# Add layer control\n",
    "Map.addLayerControl()\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c48c2",
   "metadata": {},
   "source": [
    "## Downloading Pre- and Post-Flood NDWI Images\n",
    "\n",
    "We calculate NDWI for pre- and post-flood Sentinel-2 images and download them as PNG files.  \n",
    "This allows us to keep local copies for reporting and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# Define paths\n",
    "dir = \"images/flood_maps\"\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Correct NDWI calculation\n",
    "def add_ndwi(image):\n",
    "    return image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "\n",
    "ndwi_collection = post_flood_sentinel2.map(calculate_ndwi)\n",
    "ndwi_image = ndwi_collection.median()\n",
    "\n",
    "\n",
    "# Load pre- and post-flood images\n",
    "pre_flood = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(pre_flood_start, pre_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 70)) \\\n",
    "    .map(add_ndwi) \\\n",
    "    .median()\n",
    "\n",
    "post_flood = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 70)) \\\n",
    "    .map(add_ndwi) \\\n",
    "    .median()\n",
    "\n",
    "# Function to save Earth Engine thumbnail\n",
    "def save_ee_thumbnail(image, params, filename):\n",
    "    url = image.getThumbURL(params)\n",
    "    urllib.request.urlretrieve(url, f\"{dir}/{filename}\")\n",
    "    print(f\"Saved: {dir}/{filename}\")\n",
    "\n",
    "# Download NDWI images\n",
    "save_ee_thumbnail(\n",
    "    pre_flood.clip(aoi),\n",
    "    {'bands': ['NDWI'], 'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'blue'], 'dimensions': 1024},\n",
    "    \"pre_flood_ndwi.png\"\n",
    ")\n",
    "\n",
    "save_ee_thumbnail(\n",
    "    post_flood.clip(aoi),\n",
    "    {'bands': ['NDWI'], 'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'blue'], 'dimensions': 1024},\n",
    "    \"post_flood_ndwi.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea95f67",
   "metadata": {},
   "source": [
    "# Flood Detection Using NDWI and SAR Difference\n",
    "\n",
    "We use Sentinel-2 to detect water areas with NDWI and Sentinel-1 SAR data to detect changes after flooding.  \n",
    "The NDWI water mask and the SAR flood mask are both added to the map for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 image\n",
    "sentinel2_image = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate('2023-09-01', '2023-11-30') \\\n",
    "    .sort('CLOUDY_PIXEL_PERCENTAGE') \\\n",
    "    .first()\n",
    "\n",
    "# Calculate NDWI\n",
    "ndwi_image = sentinel2_image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "\n",
    "# Apply NDWI threshold\n",
    "# Threshold NDWI\n",
    "ndwi_threshold = 0.01\n",
    "ndwi = ndwi_image.select('NDWI').gt(ndwi_threshold)\n",
    "\n",
    "# Mask non-water\n",
    "ndwi_water = ndwi.selfMask()\n",
    "\n",
    "# Visualize NDWI water\n",
    "Map.addLayer(ndwi_water.clip(aoi), {'palette': ['blue']}, 'NDWI Water Mask')\n",
    "\n",
    "\n",
    "\n",
    "# Load Sentinel-1 images\n",
    "pre_flood_sar = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(pre_flood_start, pre_flood_end) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')) \\\n",
    "    .mean()\n",
    "\n",
    "post_flood_sar = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')) \\\n",
    "    .mean()\n",
    "\n",
    "# Calculate SAR difference\n",
    "sar_diff = pre_flood_sar.select('VV').subtract(post_flood_sar.select('VV'))\n",
    "\n",
    "# Create flood mask\n",
    "flood_mask = sar_diff.gt(1).selfMask()\n",
    "\n",
    "# Compares with the Sentinel-1 flood mask\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'green']}, 'Sentinel-1 Flood Mask')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787299c",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "This code creates a mask (a special filter) to highlight only the water areas on the map. It looks at the NDWI values and decides which pixels are water and which are not water.\n",
    "\n",
    "\n",
    "Sentinel-1 is another satellite (different from Sentinel-2).\n",
    "\n",
    "\n",
    "\n",
    "Validation We want to make sure that the places we found as flooded are really flooded.\n",
    "NDWI Water Mask: We use the NDWI (Normalized Difference Water Index) from Sentinel-2 to identify water areas and compare it with the flood mask from Sentinel-1.\n",
    "\n",
    "Comparing with the Sentinel-1 Flood Mask:\n",
    "\n",
    "Explanation: We add the flood mask from Sentinel-1 to the map, using green to show the areas identified as flooded. This allows us to visually compare the two masks.\n",
    "\n",
    "Flood detection using Sentinel-1 SAR data relies on the principle that surface water reduces radar backscatter intensity. \n",
    "By calculating the difference between pre-flood and post-flood VV backscatter, and applying a threshold (e.g., > 1 dB decrease), flood-affected areas can be identified and mapped.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7f6b3",
   "metadata": {},
   "source": [
    "## Cleaning the Flood Mask with Connected Components\n",
    "\n",
    "We remove small isolated patches by keeping only larger connected flood areas.  \n",
    "This helps clean the flood mask and focus on meaningful flooded regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply connected component labeling correctly\n",
    "cleaned_flood_mask = flood_mask.connectedComponents(\n",
    "    ee.Kernel.plus(1),  # 4-connected neighborhood\n",
    "    128                 # Maximum size (arbitrary large number)\n",
    ").select('labels')\n",
    "\n",
    "# Filter: Keep only clusters bigger than 8 pixels\n",
    "flood_mask_clean = cleaned_flood_mask.gte(8).selfMask()\n",
    "\n",
    "# Visualize cleaned flood mask\n",
    "Map.addLayer(flood_mask_clean.clip(aoi), {'palette': ['green']}, 'Cleaned Sentinel-1 Flood Mask')\n",
    "Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4118d41",
   "metadata": {},
   "source": [
    "A connected component analysis with a 4-neighborhood (plus-shaped kernel) was used to filter out isolated noise pixels from the Sentinel-1 flood mask. Only connected regions larger than 8 pixels were retained as valid flood detections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e9af2",
   "metadata": {},
   "source": [
    "Visualizing final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results on the map\n",
    "Map = geemap.Map()\n",
    "Map.addLayer(pre_flood_image.clip(aoi), {'min': -25, 'max': 0}, 'Pre-Flood Sentinel-1')\n",
    "Map.addLayer(post_flood_image.clip(aoi), {'min': -25, 'max': 0}, 'Post-Flood Sentinel-1')\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'Flood Mask')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8643325f",
   "metadata": {},
   "source": [
    "Display pre-flood and post-flood Sentinel-1 radar images using appropriate visualization settings (min=-25, max=0).\n",
    "\n",
    "Add computed flood mask layer (blue palette) for easy flood detection visualization.\n",
    "\n",
    "Center the map over the Area of Interest (AOI).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea63db5",
   "metadata": {},
   "source": [
    "## Exporting Water and Flood Masks to Google Drive\n",
    "\n",
    "We export the NDWI water mask and the SAR flood mask to Google Drive.  \n",
    "These exported images can be used for validation, visualization, and reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e007ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export NDWI water mask\n",
    "task_ndwi = ee.batch.Export.image.toDrive(\n",
    "    image=ndwi.clip(aoi),\n",
    "    description='NDWI_WaterMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=10,\n",
    "    region=aoi\n",
    ")\n",
    "task_ndwi.start()\n",
    "\n",
    "# Export flood mask to Google Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=flood_mask.clip(aoi),\n",
    "    description='FloodMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=30,\n",
    "    region=aoi\n",
    ")\n",
    "task.start()\n",
    "print(\"Export task started. Check Google Drive for results.\")\n",
    "print(\"Export tasks started. Check Google Drive for the validation results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a73ec",
   "metadata": {},
   "source": [
    "## Loading and Visualizing the Exported Flood Mask\n",
    "\n",
    "We check if the exported flood mask file exists locally.  \n",
    "If found, the mask is loaded and displayed to verify the flood detection results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e9ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Sentinel-1 flood mask file exists\n",
    "flood_mask_path = r\"C:\\\\Users\\\\Neo\\\\Desktop\\\\FYP\\\\GEEgoogledrive\\\\FloodMask.tif\"\n",
    "if os.path.exists(flood_mask_path):\n",
    "    # Open the exported Sentinel-1 flood mask\n",
    "    with rasterio.open(flood_mask_path) as src:\n",
    "        flood_mask_image = src.read(1)\n",
    "\n",
    "    # Display the Sentinel-1 flood mask\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(flood_mask_image, cmap='Greens', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Sentinel-1 Flood Mask')\n",
    "    plt.title('Sentinel-1 Flood Mask')\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"File not found: {flood_mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff20c89",
   "metadata": {},
   "source": [
    "# Anazyling results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e51d1",
   "metadata": {},
   "source": [
    "## Comparing Flood Mask and Water Mask\n",
    "\n",
    "We load post-flood Sentinel-2 images and display both the SAR-based flood mask and the NDWI water mask.  \n",
    "This visual comparison helps evaluate the flood detection accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53eb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 imagery for the post-flood period\n",
    "post_flood_sentinel2 = ee.ImageCollection('COPERNICUS/S2') \\\n",
    "    .filterBounds(aoi) \\\n",
    "    .filterDate(post_flood_start, post_flood_end) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 80))  # Filter out cloudy images\n",
    "\n",
    "# Check\n",
    "# Add the flood mask and NDWI water mask for comparison\n",
    "Map.addLayer(flood_mask.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'green']}, 'Sentinel-1 Flood Mask')\n",
    "Map.addLayer(ndwi.clip(aoi), {'min': 0, 'max': 1, 'palette': ['white', 'blue']}, 'NDWI Water Mask')\n",
    "\n",
    "\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c98f6d",
   "metadata": {},
   "source": [
    "## Creating and Visualizing the Confusion Matrix\n",
    "\n",
    "We compare the Sentinel-1 flood mask against the NDWI water mask by building a confusion matrix.  \n",
    "Each color shows where predictions matched or differed from the reference water data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae7775",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For demonstration, we'll use the NDWI water mask as validation data\n",
    "reference_data = ndwi\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_matrix = flood_mask.add(reference_data.multiply(2)).clip(aoi)\n",
    "\n",
    "# Add confusion matrix to the map\n",
    "Map.addLayer(confusion_matrix, {'min': 0, 'max': 3, 'palette': ['white', 'green', 'blue', 'red']}, 'Confusion Matrix')\n",
    "Map.centerObject(aoi)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c688aae",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "The NDWI water mask (blue) represents water bodies detected by Sentinel-2.\n",
    "\n",
    "The Sentinel-1 flood mask (green) represents flooded areas detected by Sentinel-1.\n",
    "\n",
    "Overlaying the two masks to see how well they align.\n",
    "\n",
    "Here we look for areas where both masks (blue and green) overlap. These are likely true flooded areas.\n",
    "\n",
    "Areas where only one mask detects water may indicate false positives or false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffad09",
   "metadata": {},
   "source": [
    "Quantitive Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cc1b5",
   "metadata": {},
   "source": [
    "EXPLANATION \n",
    "\n",
    "True Positives (TP): Areas where both Sentinel-1 and NDWI detect water.\n",
    "\n",
    "False Positives (FP): Areas where Sentinel-1 detects water, but NDWI does not.\n",
    "\n",
    "False Negatives (FN): Areas where NDWI detects water, but Sentinel-1 does not.\n",
    "\n",
    "Accuracy: Percentage of correctly identified flooded areas.\n",
    "\n",
    "Precision: Percentage of detected floods that are correct.\n",
    "\n",
    "Recall: Percentage of actual floods that were detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1222d",
   "metadata": {},
   "source": [
    "## Debugging \n",
    "\n",
    "## Counting Pixels in Each Mask\n",
    "\n",
    "We calculate the total number of pixels flagged as flooded in the SAR flood mask  \n",
    "and in the NDWI water mask. This helps quantify and compare the detection results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many pixels are flagged in each mask\n",
    "print(\"Flood mask pixel count:\", flood_mask.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())\n",
    "print(\"NDWI water mask pixel count:\", ndwi.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07210866",
   "metadata": {},
   "source": [
    "## Calculating NDWI Statistics\n",
    "\n",
    "We calculate the minimum, maximum, and mean NDWI values over the area of interest.  \n",
    "These statistics help guide threshold selection for detecting water.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab726224",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndwi_stats = ndwi_image.select('NDWI').reduceRegion(\n",
    "    ee.Reducer.minMax().combine(ee.Reducer.mean(), None,True),\n",
    "    aoi,\n",
    "    30\n",
    ").getInfo()\n",
    "print(\"NDWI statistics:\", ndwi_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd211ea8",
   "metadata": {},
   "source": [
    "## Adjusting the NDWI Threshold Dynamically\n",
    "\n",
    "We adjust the NDWI threshold based on the mean NDWI value to improve water detection.  \n",
    "After applying the new threshold, we recheck how many pixels are classified as water.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean NDWI dynamically\n",
    "new_threshold = ndwi_stats['NDWI_mean'] * 1.2  # 20% above the mean NDWI value\n",
    "ndwi = ndwi_image.select('NDWI').gt(0.1).rename('NDWI_WATER')\n",
    "\n",
    "# Recheck water pixels\n",
    "print(\"New water pixels:\", ndwi.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e8506",
   "metadata": {},
   "source": [
    "## Validating Flood Detection with JRC Water Data\n",
    "\n",
    "We compare the detected flooded areas with the JRC permanent water dataset.  \n",
    "This helps validate how much of the detected flood overlaps with known water bodies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630688ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing with a known water source (permanent water from JRC)\n",
    "# Load JRC permanent water dataset\n",
    "jrc_water = ee.ImageCollection(\"JRC/GSW1_4/YearlyHistory\") \\\n",
    "    .filter(ee.Filter.eq('year', 2021)) \\\n",
    "    .first() \\\n",
    "    .eq(2) # Permanent water\n",
    "\n",
    "# JRC water added layer to the map\n",
    "Map.addLayer(jrc_water.clip(aoi), {'palette': ['blue']}, 'JRC Permanent Water')\n",
    "\n",
    "# Compare overlap with NDWI water mask\n",
    "flood_water_overlap = flood_mask.And(jrc_water)\n",
    "print(\"Flood mask overlap with JRC water:\", flood_water_overlap.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523ef47",
   "metadata": {},
   "source": [
    "The YearlyHistory band contains classifications for each pixel, where:​\n",
    "\n",
    "0 indicates no water detected,\n",
    "\n",
    "1 indicates seasonal water, and\n",
    "\n",
    "2 indicates permanent water.​\n",
    "\n",
    "By applying .eq(2), you're creating a binary mask highlighting areas classified as permanent water."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080646f",
   "metadata": {},
   "source": [
    "## Reprojecting Images for Consistency\n",
    "\n",
    "Reprojects the flood mask and JRC water data to a common coordinate system and resolution.  \n",
    "This ensures accurate overlap comparison between different datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec676479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the projection() or resolution of Sentinel-1 vs Sentinel-2 vs JRC can differ.\n",
    "# Reproject to a common CRS and scale (e.g., EPSG:4326, 30m)\n",
    "flood_mask = flood_mask.reproject(crs='EPSG:4326', scale=30)\n",
    "jrc_water = jrc_water.reproject(crs='EPSG:4326', scale=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c155101c",
   "metadata": {},
   "source": [
    "## Exporting and Visualizing the Final Flood Mask\n",
    "\n",
    "Compares the final flood mask with JRC water data, export it to Google Drive,  \n",
    "and also visualize it locally by converting it into a NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_water_overlap = flood_mask.And(jrc_water)\n",
    "print(\"Flood mask overlap with JRC water:\", flood_water_overlap.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())\n",
    "# Export the flood mask to Google Drive\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=flood_mask.clip(aoi),\n",
    "    description='FloodMask',\n",
    "    folder='EarthEngineImages',\n",
    "    scale=30,\n",
    "    region=aoi\n",
    ")\n",
    "task.start()\n",
    "print(\"Export task started. Check Google Drive for the flood mask.\")\n",
    "\n",
    "# Converts the flood_mask to a NumPy array for visualization\n",
    "flood_mask_array = geemap.ee_to_numpy(flood_mask, region=aoi, scale=30)\n",
    "\n",
    "# Checks if the array is valid\n",
    "if flood_mask_array is not None:\n",
    "    plt.imshow(flood_mask_array, cmap='Blues', vmin=0, vmax=1)\n",
    "    plt.colorbar(label='Flood Mask')\n",
    "    plt.title('Flood Mask')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Failed to convert flood_mask to a NumPy array.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073dfb7",
   "metadata": {},
   "source": [
    "## Visualizing and Downloading Final Validation Layers\n",
    "\n",
    "We visualize the flood mask, JRC water map, and their overlap.  \n",
    "Each layer is also saved locally as a PNG file for reporting and validation purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=[51.7, -8.35], zoom=10)\n",
    "\n",
    "Map.addLayer(flood_mask.updateMask(flood_mask).clip(aoi), {'palette': ['cyan']}, 'Flood Mask')\n",
    "Map.addLayer(jrc_water.updateMask(jrc_water).clip(aoi), {'palette': ['blue']}, 'JRC Water')\n",
    "Map.addLayer(flood_water_overlap.updateMask(flood_water_overlap).clip(aoi), {'palette': ['purple']}, 'Flood ∩ Water')\n",
    "\n",
    "\n",
    "\n",
    "def download_layer_as_png(image, filename, palette, min_val=0, max_val=1):\n",
    "    folder = r'C:\\Users\\Neo\\Desktop\\FYP\\Flood-Detection-System-FYP\\Gee\\images\\validation'  # Folder where you want to save\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder):\n",
    "        raise FileNotFoundError(f\"The folder '{folder}' does not exist. Please create it first.\")\n",
    "\n",
    "    try:\n",
    "        # Generate thumbnail URL\n",
    "        url = image.getThumbURL({\n",
    "            'dimensions': 1024,\n",
    "            'region': aoi.getInfo()['coordinates'],\n",
    "            'format': 'png',\n",
    "            'min': min_val,\n",
    "            'max': max_val,\n",
    "            'palette': palette\n",
    "        })\n",
    "\n",
    "        # Download the image from the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            full_path = os.path.join(folder, filename)\n",
    "            with open(full_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Saved {full_path}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {filename}: {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {filename}: {e}\")\n",
    "\n",
    "# Flood Mask (Cyan)\n",
    "download_layer_as_png(\n",
    "    flood_mask,\n",
    "    'flood_mask.png',\n",
    "    palette=['cyan']\n",
    ")\n",
    "\n",
    "# JRC Water (Blue)\n",
    "download_layer_as_png(\n",
    "    jrc_water,\n",
    "    'jrc_water.png',\n",
    "    palette=['blue']\n",
    ")\n",
    "\n",
    "# Flood ∩ Water (Purple)\n",
    "download_layer_as_png(\n",
    "    flood_water_overlap,\n",
    "    'flood_water_overlap.png',\n",
    "    palette=['purple']\n",
    ")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87084576",
   "metadata": {},
   "source": [
    "| Layer            | Color  | Meaning                                                        |\n",
    "|------------------|--------|----------------------------------------------------------------|\n",
    "| Flood Mask       | Cyan   | Detected flood areas (from Sentinel-1 SAR)                     |\n",
    "| JRC Water        | Blue   | Permanent water bodies (from JRC dataset)                      |\n",
    "| Flood ∩ Water    | Purple | Areas where detected floods overlap with permanent water       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86733b88",
   "metadata": {},
   "source": [
    "## Final Overlap Statistics\n",
    "\n",
    "We calculate how many pixels overlap between the detected flood areas and the JRC water bodies.  \n",
    "We also print the total number of JRC water pixels for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd0b1a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flood mask overlap with JRC water: {'VV': 2448}\n",
      "JRC water pixel count: {'waterClass': 6965.956862745098}\n"
     ]
    }
   ],
   "source": [
    "print(\"Flood mask overlap with JRC water:\", flood_water_overlap.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())\n",
    "print(\"JRC water pixel count:\", jrc_water.reduceRegion(ee.Reducer.sum(), aoi, 30).getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74c1df",
   "metadata": {},
   "source": [
    "## Final Overlap Statistics\n",
    "\n",
    "Calculating how many pixels overlap between the detected flood areas and the JRC water bodies.  \n",
    "Pringing the total number of JRC water pixels for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad405b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix image\n",
    "# flood_mask = prediction; jrc_water = reference\n",
    "confusion = jrc_water.add(flood_mask.multiply(2)).clip(aoi)\n",
    "# Meaning of pixel values:\n",
    "# 0 = TN, 1 = FP, 2 = FN, 3 = TP\n",
    "\n",
    "# Extract each category\n",
    "TP = confusion.eq(3).rename('TP')\n",
    "FP = confusion.eq(1).rename('FP')\n",
    "FN = confusion.eq(2).rename('FN')\n",
    "TN = confusion.eq(0).rename('TN')\n",
    "\n",
    "# Count each category\n",
    "metrics = {\n",
    "    'TP': TP.reduceRegion(ee.Reducer.sum(), aoi, 30).get('TP'),\n",
    "    'FP': FP.reduceRegion(ee.Reducer.sum(), aoi, 30).get('FP'),\n",
    "    'FN': FN.reduceRegion(ee.Reducer.sum(), aoi, 30).get('FN'),\n",
    "    'TN': TN.reduceRegion(ee.Reducer.sum(), aoi, 30).get('TN')\n",
    "}\n",
    "\n",
    "# Retrieve and compute accuracy stats\n",
    "stats = ee.Dictionary(metrics).getInfo()\n",
    "tp, fp, fn, tn = stats['TP'], stats['FP'], stats['FN'], stats['TN']\n",
    "total = tp + fp + fn + tn\n",
    "\n",
    "accuracy = (tp + tn) / total if total else 0\n",
    "precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "F1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix Metrics\")\n",
    "print(f\"Correctly Detected Water Pixels (TP): {tp:.0f}\")\n",
    "print(f\"Incorrectly Detected Water Pixels (FP): {fp:.0f}\")\n",
    "print(f\"Missed Water Pixels (FN): {fn:.0f}\")\n",
    "print(f\"Correctly Detected Non-Water Pixels (TN): {tn:.0f}\")\n",
    "print(f\"Overall Accuracy : {accuracy:.2%}\")\n",
    "print(f\"Water Detection Precision  : {precision:.2%}\")\n",
    "print(f\"Water Detection Recall: {recall:.2%}\")\n",
    "print(f\"F1 Score: {F1_score:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0addd25",
   "metadata": {},
   "source": [
    "Final Metrics\n",
    "\n",
    "Accuracy: 6.39%\n",
    "model correctly identified flood presence or absence 6.39% of the time.\n",
    "\n",
    "Precision: 12.12%\n",
    "Of all the areas predicted as flood, only 12.12% were actually water. \n",
    "\n",
    "Recall: 6.39%\n",
    "Of all real water bodies, only 6.39% were detected. This is quite low, meaning your model is missing a lot of actual flooded areas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58111976",
   "metadata": {},
   "source": [
    "flood detection method is currently:\n",
    "\n",
    "- With low recall (misses real floods).\n",
    "\n",
    "- Not extremely noisy (Precision at 36% isn't bad), so it’s not spamming false floods.\n",
    "\n",
    "- Could benefit from tuning the NDWI threshold, improving masking (e.g., clouds), or using temporal changes (NDWI before vs after flood).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ce448",
   "metadata": {},
   "source": [
    "# Confusion Matrix with Real Numbers\n",
    "\n",
    "This shows actual counts:\n",
    "\n",
    "- **Floods correctly found** (True Positives)\n",
    "- **Places wrongly marked as floods** (False Positives)\n",
    "- **Real floods that were missed** (False Negatives)\n",
    "- **Non-floods correctly ignored** (True Negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cac09",
   "metadata": {},
   "source": [
    "## Plotting the Confusion Matrix Heatmap\n",
    "\n",
    "We build and visualize the confusion matrix using the detection results.  \n",
    "The heatmap shows how well the flood detection matched the validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collected statistics\n",
    "tp, fp, fn, tn = stats['TP'], stats['FP'], stats['FN'], stats['TN']\n",
    "\n",
    "# Create confusion matrix as a 2x2 array\n",
    "conf_matrix = np.array([[tp, fn],\n",
    "                        [fp, tn]])\n",
    "\n",
    "# Create labels for rows and columns\n",
    "labels = ['Flood', 'Non-Flood']\n",
    "df_cm = pd.DataFrame(conf_matrix, index=labels, columns=labels)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(df_cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "plt.xlabel(\"Valid Data\")\n",
    "plt.ylabel(\"Detection\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/charts/confusion_matrix_heatmap.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7770ea8a",
   "metadata": {},
   "source": [
    "## Plotting the Normalized Confusion Matrix\n",
    "\n",
    "We normalize the confusion matrix to show percentages instead of raw counts.  \n",
    "This helps better understand detection accuracy in a clear and visual way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = np.array([[tp, fn],\n",
    "                        [fp, tn]])\n",
    "\n",
    "# Normalize the matrix \n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a DataFrame with percentage formatting\n",
    "df_cm_norm = pd.DataFrame(conf_matrix_normalized,\n",
    "                          index=['Detected: Flood', 'Detected: Non-Flood'],\n",
    "                          columns=['Valid Data: Flood', 'Valid Data: Non-Flood'])\n",
    "\n",
    "# Plot the percentage heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(df_cm_norm, annot=True, fmt='.2%', cmap='YlGnBu', cbar=True)\n",
    "plt.title(\"Precentage Confusion Matrix Heatmap\")\n",
    "plt.xlabel(\"Valid Data\")\n",
    "plt.ylabel(\"Detection\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/charts/confusion_matrix_heatmap_percentages.png',  dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fedf44",
   "metadata": {},
   "source": [
    "# Result Analysis\n",
    "\n",
    "## 10.2 Visual Analysis\n",
    "\n",
    "Flooded areas detected using the Sentinel-1 SAR backscatter threshold method were predominantly displayed in green, while the water bodies identified using NDWI were displayed in blue.\n",
    "\n",
    "A confusion matrix map was also created for agreement and disagreement identification between the two methods:\n",
    "- **Red areas** represented true positive matches (flood detected by both the methods).\n",
    "- **Green areas** represented false positives (flood detected by SAR but not by NDWI).\n",
    "- **Blue areas** were false negatives (flood detected by NDWI but not by SAR).\n",
    "- **White areas** were correctly detected non-flood areas.\n",
    "\n",
    "## 10.3 Quantitative Assessment\n",
    "\n",
    "A confusion matrix was constructed, and crucial evaluation measures were derived:\n",
    "\n",
    "- **Correctly Detected Water Pixels (TP):** 2,448\n",
    "- **Incorrectly Detected Water Pixels (FP):** 0\n",
    "- **Missed Water Pixels (FN):** 35,887\n",
    "- **Correctly Detected Non-Water Pixels (TN):** 0\n",
    "\n",
    "The resultant performance measures were:\n",
    "- **Overall Accuracy:** 6.39%\n",
    "- **Water Detection Precision:** 100.00%\n",
    "- **Water Detection Recall:** 6.39%\n",
    "- **F1 Score:** 11.96%\n",
    "\n",
    "## 10.4 Interpretation\n",
    "\n",
    "The model of flood detection demonstrated extremely high precision, the correct match between detected flood pixel and flooded region.\n",
    "But low recall value indicates that most flooded regions were undetected.\n",
    "This means the SAR flood detection method was did not work in perfect conditions, excluding false positives at the cost of missing significant parts of the flooded regions.\n",
    "\n",
    "The absence of non-flood detection within the confusion matrix illustrates the data properties and not a procedural defect.\n",
    "AOI predominantly covered flood-affected regions all over the event, and cloud cover in Sentinel-2 images could have contributed towards masking non-flooded pixels.\n",
    "\n",
    "## 10.5 Limitations\n",
    "\n",
    "Some limitations affected the analysis:\n",
    "- Optical image cloud cover and masking of images constrained the validation dataset.\n",
    "- SAR may not detect shallow, vegetated, or small flood areas.\n",
    "\n",
    "## 10.6 Conclusion\n",
    "\n",
    "The model for detecting floods was overall effective in detecting flooded regions correctly where it did detect them, but there is future work that should focus on boosting recall by the use of more combined radar and optical techniques, adaptive thresholding and some other processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6dc6fc",
   "metadata": {},
   "source": [
    "# Conclusion and Future Work\n",
    "\n",
    "## 11.1 Conclusion\n",
    "\n",
    "The project successfully demonstrated a flood detection workflow based on Sentinel-1 SAR images that was validated against an NDWI-based water mask created from Sentinel-2 optical data.\n",
    "The procedure involved preprocessing, flood mask generation, NDWI calculation, confusion matrix creation, and performance evaluation.\n",
    "\n",
    "The results highlighted the advantages and disadvantages of the SAR-based flood detection method:\n",
    "- The accuracy of the flood mask was 100%, i.e., all the detected floods were real flooded areas.\n",
    "- The recall was very low (6.39%), i.e., most of the flooded areas were not identified.\n",
    "- The accuracy overall was 6.39%, which was significantly impacted by the biased ratio of flooded to non-flooded areas in the data.\n",
    "\n",
    "These findings suggest that while Sentinel-1 is extremely accurate in precisely detecting floodwaters when detected, it fails to detect smaller or less evident flood occurrences, particularly under vegetative cover or in shallow water cases.\n",
    "\n",
    "The study also demonstrated the challenges of validating floods in the absence of authoritative ground truth information.\n",
    "Using NDWI as pseudo-reference was an expedient remedy, but cloud cover and optical data gaps place limitations that should be acknowledged.\n",
    "\n",
    "Notwithstanding these challenges, the workflow was efficient and scalable and presented a platform for making improvements to future automated flood detection systems from Earth Observation data.\n",
    "\n",
    "## 11.2 Future Work\n",
    "\n",
    "A number of ways are open for further developing this work:\n",
    "\n",
    "- **Better Validation Data:** Adding authoritative flood maps (e.g., Copernicus EMS) or manual annotation through high-resolution images might allow a stronger validation dataset.\n",
    "- **Threshold Optimization:** Local image statistics-based dynamic thresholding rather than using fixed values may improve the sensitivity of flood detection.\n",
    "- **Multisensor Fusion:** Decision-level or pixel-level fusion of SAR and optical images may improve the strengths of each data type.\n",
    "- **Machine Learning Approaches:** Applying supervised classification techniques (e.g., Random Forest, CNNs) learned from flood/non-flood examples may yield better detection accuracy.\n",
    "- **Temporal Analysis:** Combining time-series SAR image analysis could potentially differentiate better between permanent and temporary water bodies and flood events.\n",
    "- **Cloud-Free Optical Reference:** Use of different data could possibly overcome cloud-cover constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52793c42",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
